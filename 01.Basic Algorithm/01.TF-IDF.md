# TF-IDF

TF-IDF（term frequency-inverse document frequency，词频-逆文档频率）是一种用于信息检索和文本挖掘的常用加权技术。其是一种统计方法，用于评估「一个字词对于一个文件集或一个语料库中的其中一份文件」的重要程度。一个字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。

TF-IDF的基本思想就是：如果一个单词在一篇文章中出现的频率TF高，但是在其他文章中很少出现，则认为该词具有很好的类别区分能力，适合用来分类

## 计算

给定文档集合D，一个单词t对于某文档d的TF-IDF值计算方式：
$$
tfidf(t, d, D) = tf(t, d) *idf(t, D)
$$
所以在文档集合D中，某个特定单词针对某文档d的TF_IDF值实际上是由两部分构成

### TF：词频（Term ferquency）

词频表示某词在某篇文章中出现的频率：
$$
tf(t, d) = \frac{f_{t, d}}{\sum\limits_{t^{'}\in d}{f_{t^{'},d}}}
$$
其中$f_{t,d}$是单词t在文档d中的出现次数，上式右项的分母表示「文档d中的单词出现次数之和」，可以简单理解为文档d中的单词数

### IDF：逆文档频率（Inverse document frequency）

某一单词的IDF，可以由「总文档个数除以包含有该单词的文件数目，然后将该商取对数」得到：
$$
idf(t, D) = log{\frac{|D|}{|{d \in D : t \in d}|}} = -log{\frac{|d \in D:t \in d|}{|D|}}
$$
其中$|D|$表示该文档集合D中的文档个数，上式最右项的分子$|d\in D : t\in d|$表示「文档集合D中出现过单词t的文档个数」

# 参考

1. [TF-IDF算法介绍及实现](https://blog.csdn.net/asialee_bird/article/details/81486700)
2. [Understanding TF-ID: A Simple Introduction](https://monkeylearn.com/blog/what-is-tf-idf/#:~:text=TF%2DIDF%20(term%20frequency%2D,across%20a%20set%20of%20documents.)
3. [tf–idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)